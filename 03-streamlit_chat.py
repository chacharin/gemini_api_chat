import streamlit as st
import google.generativeai as genai

# ---------------- Page & App setup ------------------
st.set_page_config(
    page_title="‡πÅ‡∏ä‡∏ó‡∏ö‡∏≠‡∏ó‡∏™‡∏∏‡∏î‡∏¢‡∏≠‡∏î‡∏ô‡∏±‡∏Å‡∏õ‡∏•‡∏π‡∏Å üå±",
    page_icon="üå±",
    layout="centered",
)

st.title("üå± ‡πÅ‡∏ä‡∏ó‡∏ö‡∏≠‡∏ó‡∏™‡∏∏‡∏î‡∏¢‡∏≠‡∏î‡∏ô‡∏±‡∏Å‡∏õ‡∏•‡∏π‡∏Å")
st.caption("‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏Å‡∏≤‡∏£‡∏õ‡∏•‡∏π‡∏Å‡∏û‡∏∑‡∏ä‡∏ú‡∏±‡∏Å‡∏™‡∏ß‡∏ô‡∏Ñ‡∏£‡∏±‡∏ß‡∏î‡πâ‡∏ß‡∏¢ Gemini 1.5-Flash")

# ---------------- API-Key (Embedded) ------------------
API_KEY = "AIzaSyBIVkeXW7JpZzQxJZY72ZlO0lHxFYEpuMk"  # ‚õîÔ∏è ‡∏Ñ‡∏µ‡∏¢‡πå‡∏ù‡∏±‡∏á‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ ‡πÑ‡∏°‡πà‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏Ñ‡πâ‡∏î‡∏™‡∏≤‡∏ò‡∏≤‡∏£‡∏ì‡∏∞!

genai.configure(api_key=API_KEY)

# ---------------- Gemini model setup ----------------
SYSTEM_INSTRUCTION = (
    "‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏∏‡∏î‡∏¢‡∏≠‡∏î‡πÄ‡∏Å‡∏©‡∏ï‡∏£‡∏Å‡∏£‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏°‡∏≤‡∏Å‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏•‡∏π‡∏Å‡∏û‡∏∑‡∏ä‡∏ú‡∏±‡∏Å‡∏™‡∏ß‡∏ô‡∏Ñ‡∏£‡∏±‡∏ß "
    "‡πÇ‡∏õ‡∏£‡∏î‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏â‡∏±‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢"
)
GENERATION_CONFIG = {"temperature": 0.7}

# Initialise the model & chat object once per session ----------------
if "chat" not in st.session_state:
    model = genai.GenerativeModel(
        model_name="gemini-1.5-flash",
        system_instruction=SYSTEM_INSTRUCTION,
        generation_config=GENERATION_CONFIG,
    )
    st.session_state.chat = model.start_chat(history=[])

chat = st.session_state.chat

# ---------------- Display previous messages ----------------
for turn in chat.history:
    role = "assistant" if turn.role == "model" else "user"
    with st.chat_message(role):
        st.markdown(turn.parts[0].text)

# ---------------- Prompt box ----------------
if prompt := st.chat_input("‡∏ñ‡∏≤‡∏°‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏Å‡∏≤‡∏£‡∏õ‡∏•‡∏π‡∏Å‡∏û‡∏∑‡∏ä‡∏ú‡∏±‡∏Å‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà ‡πÅ‡∏•‡πâ‡∏ß‡∏Å‡∏î Enter ‚Ä¶"):
    # Show user message immediately
    with st.chat_message("user"):
        st.markdown(prompt)

    # Get response from Gemini
    try:
        response = chat.send_message(prompt)
        with st.chat_message("assistant"):
            st.markdown(response.text)
    except Exception as err:
        st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {err}")
